{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d043490e",
   "metadata": {},
   "source": [
    "# Further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c9c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d6743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assuming you've already run the previous functions to create:\n",
    "# - stable_timeseries = create_stable_point_timeseries(timeseries)\n",
    "# - features_df = extract_ml_features(stable_timeseries)\n",
    "\n",
    "# 1. Check feature distribution and handle missing values\n",
    "print(f\"Feature dataset shape: {features_df.shape}\")\n",
    "print(f\"Missing values: {features_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Fill missing values with median\n",
    "features_df = features_df.fillna(features_df.median())\n",
    "\n",
    "# 2. Prepare features and target\n",
    "X = features_df.drop(['point_id', 'point_lon', 'point_lat', 'is_damaged'], axis=1)\n",
    "y = features_df['is_damaged']\n",
    "\n",
    "# 3. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"Class distribution in training: {np.bincount(y_train)}\")\n",
    "print(f\"Class distribution in testing: {np.bincount(y_test)}\")\n",
    "\n",
    "# 4. Create a pipeline with preprocessing and model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 5. Define hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 6. Perform cross-validation and grid search\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid, cv=cv, scoring='f1', verbose=1, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 7. Print best parameters and score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 8. Evaluate the model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 9. Print classification metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 10. Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Undamaged', 'Damaged'],\n",
    "            yticklabels=['Undamaged', 'Damaged'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 11. Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# 12. Plot Precision-Recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 13. Feature importance analysis\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_model.named_steps['classifier'].feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importances.head(20))\n",
    "plt.title('Top 20 Most Important Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 14. Analyze errors\n",
    "errors = pd.DataFrame({\n",
    "    'actual': y_test,\n",
    "    'predicted': y_pred,\n",
    "    'probability': y_pred_proba,\n",
    "    'error': y_test != y_pred\n",
    "})\n",
    "\n",
    "# Add original point coordinates\n",
    "errors = errors.reset_index().merge(\n",
    "    features_df[['point_id', 'point_lon', 'point_lat']], \n",
    "    left_on='index', right_index=True, how='left'\n",
    ")\n",
    "\n",
    "# False positives (predicted damaged but actually undamaged)\n",
    "false_positives = errors[(errors['error']) & (errors['predicted'] == 1)]\n",
    "print(f\"\\nFalse positives: {len(false_positives)} points\")\n",
    "\n",
    "# False negatives (predicted undamaged but actually damaged)\n",
    "false_negatives = errors[(errors['error']) & (errors['predicted'] == 0)]\n",
    "print(f\"False negatives: {len(false_negatives)} points\")\n",
    "\n",
    "# Save error analysis for potential visual inspection\n",
    "false_positives.to_csv('false_positives.csv', index=False)\n",
    "false_negatives.to_csv('false_negatives.csv', index=False)\n",
    "\n",
    "# 15. Save the trained model\n",
    "import joblib\n",
    "joblib.dump(best_model, 'damage_detection_model.pkl')\n",
    "\n",
    "print(\"\\nModel training and evaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
